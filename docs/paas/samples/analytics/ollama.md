---
layout: docwithnav-paas
title: Running AI on Your Own Hardware - Securing Ollama with an Nginx Reverse Proxy
description: Secure your local Ollama LLM deployment with Nginx and Docker Compose. This step-by-step guide provides copy-paste commands to easily set up username/password or API key authentication, including how to connect securely from ThingsBoard.
---

{% assign docsPrefix = "paas/" %}
{% include get-hosts-name.html docsPrefix=docsPrefix %}
{% include /docs/samples/analytics/ollama.md %}
